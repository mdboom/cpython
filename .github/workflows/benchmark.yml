name: Benchmarks

on: [pull_request]

jobs:
  compile_head:
    name: 'Compiling merge branch of PR'
    runs-on: ubuntu-latest
    steps:
    - name: Cache
      id: cache
      uses: actions/cache@v3
      with:
        path: head
        key: head-${{ github.event.pull_request.head.sha }}
    - uses: actions/checkout@v3
    - name: Install Dependencies
      run: sudo ./.github/workflows/posix-deps-apt.sh
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> $GITHUB_ENV
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1
    - name: Build head version
      if: steps.cache.outputs.cache-hit != 'true'
      run: |
        ./configure --with-lto --enable-optimizations --prefix=$PWD/head
        make -j4
        make install

  compile_base:
    name: 'Compiling base branch of PR'
    runs-on: ubuntu-latest
    steps:
    - name: Cache
      id: cache
      uses: actions/cache@v3
      with:
        path: base
        key: base-${{ github.event.pull_request.base.sha }}
    - uses: actions/checkout@v3
    - name: Install Dependencies
      run: sudo ./.github/workflows/posix-deps-apt.sh
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> $GITHUB_ENV
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1
    - name: Build base version
      if: steps.cache.outputs.cache-hit != 'true'
      run: |
        # Github doesn't do full checkouts so we need to explicitly fetch the base commit
        git fetch --depth=1 origin ${{ github.event.pull_request.base.sha }}
        git checkout ${{ github.event.pull_request.base.sha }}
        git clean -fxd
        ./configure --with-lto --enable-optimizations --prefix=$PWD/base
        make -j4
        make install

  list_benchmarks:
    name: 'Determine list of all benchmarks'
    runs-on: ubuntu-latest
    steps:
    - name: Install pyperformance
      run: |
        pip install pyperformance
    - name: Get benchmarks
      id: get_benchmarks
      run: |
        python -m pyperformance list | python -c "import sys; print('::set-output name=benchmark_matrix::' + repr([x[2:] for x in sys.stdin.readlines() if x.startswith('- ')]))"
    outputs:
      benchmark_matrix:
        ${{ steps.get_benchmarks.outputs.benchmark_matrix }}

  run_benchmarks:
    name: 'Running benchmarks'
    runs-on: ubuntu-latest
    needs: [compile_head, compile_base, list_benchmarks]
    continue-on-error: true
    strategy:
      matrix:
        benchmark: ${{ fromJson(needs.list_benchmarks.outputs.benchmark_matrix) }}
    steps:
    - name: Restore base build
      uses: actions/cache@v3
      with:
        path: base
        key: base-${{ github.event.pull_request.base.sha }}
    - name: Restore head build
      uses: actions/cache@v3
      with:
        path: head
        key: head-${{ github.event.pull_request.head.sha }}
    - uses: actions/download-artifact@v3
    - name: Install pyperformance
      run: |
        python -m pip install pyperformance
        sudo python -m pip install pyperf
    - name: Tune system
      run: |
        sudo python -m pyperf system tune
    - name: Run benchmarks
      run: |
        python -m pyperformance run -b ${{ matrix.benchmark }} --python=head/bin/python3 --append head-${{ matrix.benchmark }}.json
        python -m pyperformance run -b ${{ matrix.benchmark }} --python=base/bin/python3 --append base-${{ matrix.benchmark }}.json
        python -m pyperformance run -b ${{ matrix.benchmark }} --python=head/bin/python3 --append head-${{ matrix.benchmark }}.json
        python -m pyperformance run -b ${{ matrix.benchmark }} --python=base/bin/python3 --append base-${{ matrix.benchmark }}.json
    - name: Archive results
      uses: actions/upload-artifact@v3
      with:
        name: ${{ matrix.benchmark }}
        path: |
          head-${{ matrix.benchmark }}.json
          base-${{ matrix.benchmark }}.json

  aggregate:
    name: "Aggregate results"
    runs-on: ubuntu-latest
    needs: [run_benchmarks]
    steps:
    - uses: actions/checkout@v3
    - uses: actions/download-artifact@v3
    - name: Install pyperf
      run: |
        sudo python -m pip install pyperf
    - name: Combine benchmarks
      run: |
        sudo apt install -y tree
        tree
        python .github/workflows/combine-benchmarks.py
    - name: Compare
      run: |
        pyperf compare_to --table --table-format=md base-combined.json head-combined.json > compare.md
    - name: Archive results
      uses: actions/upload-artifact@v3
      with:
        name: ALL_RESULTS
        path: |
          head-combined.json
          base-combined.json
          compare.md
