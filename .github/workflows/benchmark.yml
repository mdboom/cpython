name: Benchmarks

on: [pull_request]

jobs:
  compile_head:
    name: 'Compiling merge branch of PR'
    runs-on: ubuntu-latest
    steps:
    - name: Save build
      uses: actions/cache@v3
      with:
        path: head
        key: head-${{ github.event.pull_request.head.sha }}
    - uses: actions/checkout@v3
    - name: Install Dependencies
      run: sudo ./.github/workflows/posix-deps-apt.sh
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> $GITHUB_ENV
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1
    - name: Build head version
      run: |
        ./configure --with-lto --enable-optimizations --prefix=$PWD/head
        make -j4
        make install

  compile_base:
    name: 'Compiling base branch of PR'
    runs-on: ubuntu-latest
    steps:
    - name: Save build
      uses: actions/cache@v3
      with:
        path: base
        key: base-${{ github.event.pull_request.base.sha }}
    - uses: actions/checkout@v3
    - name: Install Dependencies
      run: sudo ./.github/workflows/posix-deps-apt.sh
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> $GITHUB_ENV
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1
    - name: Build base version
      run: |
        # Github doesn't do full checkouts so we need to explicitly fetch the base commit
        git fetch --depth=1 origin ${{ github.event.pull_request.base.sha }}
        git checkout ${{ github.event.pull_request.base.sha }}
        git clean -fxd
        ./configure --with-lto --enable-optimizations --prefix=$PWD/base
        make -j4
        make install

  run_benchmarks:
    name: 'Running benchmarks'
    runs-on: ubuntu-latest
    needs: [compile_head, compile_base]
    continue-on-error: true
    strategy:
      matrix:
        benchmark: ['unpickle_pure_python', 'unpickle_list', 'unpickle', 'unpack_sequence', 'tornado_http', 'telco', 'sqlite_synth', 'spectral_norm', 'richards', 'regex_v8', 'regex_effbot', 'regex_dna', 'regex_compile', 'raytrace', 'python_startup_no_site', 'python_startup', 'pyflate', 'pidigits', 'pickle_pure_python', 'pickle_list', 'pickle_dict', 'pickle', 'pathlib', 'nqueens', 'nbody', 'meteor_contest', 'mako', 'json_loads', 'json_dumps', 'html5lib', 'hexiom', 'go', 'float', 'fannkuch', 'dulwich_log', 'django_template', 'deltablue', 'crypto_pyaes', 'chaos', 'chameleon', '2to3']
    steps:
    - name: Restore base build
      uses: actions/cache@v3
      with:
        path: base
        key: base-${{ github.event.pull_request.base.sha }}
    - name: Restore head build
      uses: actions/cache@v3
      with:
        path: head
        key: head-${{ github.event.pull_request.head.sha }}
    - uses: actions/download-artifact@v3
    - name: Install pyperformance
      run: |
        python -m pip install pyperformance
        sudo python -m pip install pyperf
    - name: Tune system
      run: |
        sudo python -m pyperf system tune
    - name: Run benchmarks
      run: |
        python -m pyperformance run -b ${{ matrix.benchmark }} --python=head/bin/python3 --append head-${{ matrix.benchmark }}.json
        python -m pyperformance run -b ${{ matrix.benchmark }} --python=base/bin/python3 --append base-${{ matrix.benchmark }}.json
        python -m pyperformance run -b ${{ matrix.benchmark }} --python=head/bin/python3 --append head-${{ matrix.benchmark }}.json
        python -m pyperformance run -b ${{ matrix.benchmark }} --python=base/bin/python3 --append base-${{ matrix.benchmark }}.json
    - name: Archive results
      uses: actions/upload-artifact@v3
      with:
        name: ${{ matrix.benchmark }}
        path: |
          head-${{ matrix.benchmark }}.json
          base-${{ matrix.benchmark }}.json

  aggregate:
    name: "Aggregate results"
    runs-on: ubuntu-latest
    needs: [run_benchmarks]
    steps:
    - uses: actions/download-artifact@v3
    - uses: actions/checkout@v3
    - name: Install pyperf
      run: |
        sudo python -m pip install pyperf
    - name: Combine benchmarks
      run: |
        sudo apt install -y tree
        tree
        python .github/workflows/combine-benchmarks.py
    - name: Compare
      run: |
        pyperf compare_to --table --table-format=md base-combined.json head-combined.json > compare.md
    - name: Archive results
      uses: actions/upload-artifact@v3
      with:
        name: ALL_RESULTS
        path: |
          head-combined.json
          base-combined.json
          compare.md
